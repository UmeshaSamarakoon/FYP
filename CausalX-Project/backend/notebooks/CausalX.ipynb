{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7nJAGyle16c"
   },
   "source": [
    "**SECTION 1 — Notebook Setup**\n",
    "\n",
    "Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frpTIUQPeprM",
    "outputId": "6d746a45-3e1b-4049-f322-e6d3e7cf8cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (0.10.9)\n",
      "Requirement already satisfied: opencv-python in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (4.13.0.90)\n",
      "Requirement already satisfied: librosa in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: fastapi in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (0.128.0)\n",
      "Requirement already satisfied: uvicorn in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (0.40.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (3.10.8)\n",
      "Requirement already satisfied: seaborn in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: absl-py in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from mediapipe) (25.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from mediapipe) (25.12.19)\n",
      "Requirement already satisfied: numpy in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from mediapipe) (2.3.5)\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from mediapipe) (4.13.0.90)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from mediapipe) (0.5.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (0.63.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (1.5.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: filelock in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from torchvision) (12.1.0)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from fastapi) (0.50.0)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from fastapi) (2.12.5)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from fastapi) (0.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.11)\n",
      "Requirement already satisfied: click>=7.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from uvicorn) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.46.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from pydantic>=2.7.0->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from pydantic>=2.7.0->fastapi) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from pydantic>=2.7.0->fastapi) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2026.1.4)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install mediapipe opencv-python librosa torch torchvision torchaudio \\\n",
    "            fastapi uvicorn scikit-learn matplotlib seaborn pandas tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK3WaJwwf3WK"
   },
   "source": [
    "Imports & Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUAtTXkSf-xa",
    "outputId": "a906c8a6-2cea-40d3-ffd1-9dabe52da199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1351c5110>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrC2c6nvgLqo"
   },
   "source": [
    "**SECTION 2 — Dataset Loading & Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu2UQnBahWIE"
   },
   "source": [
    "Load Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "K76gJHx_gNfn",
    "outputId": "6fa878e0-33fc-4125-9ae4-0c1eb13c84d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jitter_mean</th>\n",
       "      <th>jitter_std</th>\n",
       "      <th>av_correlation</th>\n",
       "      <th>av_lag_frames</th>\n",
       "      <th>lip_variance</th>\n",
       "      <th>det_count</th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>video_fake</th>\n",
       "      <th>audio_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025954</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>-0.033838</td>\n",
       "      <td>-45</td>\n",
       "      <td>0.180140</td>\n",
       "      <td>300</td>\n",
       "      <td>aagfhgtpmv.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>DFDC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080513</td>\n",
       "      <td>0.141131</td>\n",
       "      <td>0.140694</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.252437</td>\n",
       "      <td>169</td>\n",
       "      <td>aapnvogymq.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>DFDC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023488</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.346990</td>\n",
       "      <td>185</td>\n",
       "      <td>0.330738</td>\n",
       "      <td>300</td>\n",
       "      <td>abarnvbtwb.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>DFDC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>0.034105</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.187281</td>\n",
       "      <td>300</td>\n",
       "      <td>abqwwspghj.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>DFDC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.128620</td>\n",
       "      <td>0.088331</td>\n",
       "      <td>-0.443419</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>19</td>\n",
       "      <td>acqfdwsrhi.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>DFDC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jitter_mean  jitter_std  av_correlation  av_lag_frames  lip_variance  \\\n",
       "0     0.025954    0.019321       -0.033838            -45      0.180140   \n",
       "1     0.080513    0.141131        0.140694             -4      0.252437   \n",
       "2     0.023488    0.030142        0.346990            185      0.330738   \n",
       "3     0.020004    0.024657        0.034105             -5      0.187281   \n",
       "4     0.128620    0.088331       -0.443419             -4      0.322993   \n",
       "\n",
       "   det_count        video_id  label dataset  video_fake  audio_fake  \n",
       "0        300  aagfhgtpmv.mp4      1    DFDC          -1          -1  \n",
       "1        169  aapnvogymq.mp4      1    DFDC          -1          -1  \n",
       "2        300  abarnvbtwb.mp4      0    DFDC          -1          -1  \n",
       "3        300  abqwwspghj.mp4      1    DFDC          -1          -1  \n",
       "4         19  acqfdwsrhi.mp4      1    DFDC          -1          -1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/venturit/Documents/GitHub/FYP/CausalX-Project/backend/data/processed/causal_multimodal_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hiCJ81Rhcmo"
   },
   "source": [
    "Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "Ao-n7ZTYhaHQ",
    "outputId": "4b3c975f-ce32-427d-9619-0dfce55f6e7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    0.974549\n",
       "0    0.025451\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov59HST3hhhO"
   },
   "source": [
    "**SECTION 3 — Preprocessing Techniques (EXPERIMENTAL)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiyDtZ73hpKC"
   },
   "source": [
    "Feature Normalization Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "STC3uH64hprF"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X = df[[\n",
    "    \"lip_variance\", \"av_correlation\", \"av_lag_frames\",\n",
    "    \"jitter_mean\", \"jitter_std\"\n",
    "]]\n",
    "\n",
    "scaler_std = StandardScaler()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "X_std = scaler_std.fit_transform(X)\n",
    "X_mm = scaler_minmax.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtceUQkphwEu"
   },
   "source": [
    "**SECTION 4 — Baseline Models (Non-Causal)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i43QV6Th7xt"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X48K6jhSh8PX",
    "outputId": "607b2b17-913a-4a3b-c1bd-a702610e63e1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(class_weight=\"balanced\")\n",
    "clf.fit(X_std, df[\"label\"])\n",
    "\n",
    "preds = clf.predict(X_std)\n",
    "probs = clf.predict_proba(X_std)[:, 1]\n",
    "\n",
    "report = classification_report(df[\"label\"], preds, output_dict=True)\n",
    "roc = roc_auc_score(df[\"label\"], probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZBBe4fKiC7O"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIZRFUjziGGn",
    "outputId": "cecfe7af-27a0-4a55-a348-15fb5e411bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       542\n",
      "           1       1.00      1.00      1.00     20754\n",
      "\n",
      "    accuracy                           1.00     21296\n",
      "   macro avg       1.00      1.00      1.00     21296\n",
      "weighted avg       1.00      1.00      1.00     21296\n",
      "\n",
      "ROC-AUC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")\n",
    "rf.fit(X_std, df[\"label\"])\n",
    "\n",
    "probs = rf.predict_proba(X_std)[:, 1]\n",
    "preds = rf.predict(X_std)\n",
    "\n",
    "print(classification_report(df[\"label\"], preds))\n",
    "print(\"ROC-AUC:\", roc_auc_score(df[\"label\"], probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC9n7e0WiIp5"
   },
   "source": [
    "**SECTION 5 — Causal Feature Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Jfl1zKxiNFg"
   },
   "source": [
    "Causal Intervention Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEzVNnSEiQKo",
    "outputId": "46e2c44f-08a3-4aa2-f098-34e1968f2f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lip_variance 0.0\n",
      "av_correlation 0.0\n",
      "av_lag_frames 0.0\n",
      "jitter_mean 9.391435011269723e-05\n",
      "jitter_std 0.0023009015777610818\n"
     ]
    }
   ],
   "source": [
    "def intervention_flip_rate(feature):\n",
    "    perturbed = X_std.copy()\n",
    "    perturbed[:, feature] = np.random.permutation(perturbed[:, feature])\n",
    "    probs = clf.predict_proba(perturbed)[:, 1]\n",
    "    return np.mean(np.abs(probs - clf.predict_proba(X_std)[:, 1]) > 0.5)\n",
    "\n",
    "features = X.columns\n",
    "for i, f in enumerate(features):\n",
    "    print(f, intervention_flip_rate(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r6navF-iZYe"
   },
   "source": [
    "**SECTION 6 — CFN (Causal Fusion Network)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D88u3ZEZieMi"
   },
   "source": [
    "CFN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "jaRUVfTaiejc"
   },
   "outputs": [],
   "source": [
    "class CausalFusionNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alpha = torch.nn.Parameter(torch.tensor(0.5))\n",
    "        self.beta = torch.nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "        self.av_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, 8),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.phys_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 8),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(8, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, av, phys):\n",
    "        fused = self.alpha * self.av_net(av) + self.beta * self.phys_net(phys)\n",
    "        return self.out(fused)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ez1xu8sijaI"
   },
   "source": [
    "CFN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHfp38Jgildp",
    "outputId": "33c86f95-630f-4fac-8793-83410d023484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0311429500579834 Beta: 0.9890584945678711\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_av = torch.tensor(X_std[:, :3], dtype=torch.float32)\n",
    "X_phys = torch.tensor(X_std[:, 3:], dtype=torch.float32)\n",
    "y = torch.tensor(df[\"label\"].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "loader = DataLoader(TensorDataset(X_av, X_phys, y), batch_size=64, shuffle=True)\n",
    "\n",
    "model = CausalFusionNetwork()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    for av, phys, label in loader:\n",
    "        opt.zero_grad()\n",
    "        loss = loss_fn(model(av, phys), label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "print(\"Alpha:\", model.alpha.item(), \"Beta:\", model.beta.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldCuh75LioSX"
   },
   "source": [
    "**SECTION 7 — Frame-Level Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-izhGJPiuK7"
   },
   "source": [
    "Frame-Level CFN Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "AjIQm-Priuo4",
    "outputId": "23657ce4-cdc1-49c9-f1f0-e3fe1d6c2f84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/backend/src/cvi/frame_causal_extractor.py:45: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(\n",
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1.0, [0.0, 0.04, 0.08, 0.12, 0.16])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "PROJECT_ROOT = \"/Users/venturit/Documents/GitHub/FYP/CausalX-Project/backend\"\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "from src.cvi.cfn_frame_inference import run_cfn_on_video\n",
    "from src.cvi.api.inference_service import summarize_video\n",
    "\n",
    "VIDEO_PATH = \"/Users/venturit/Documents/GitHub/FYP/CausalX-Project/backend/data/raw/fakeavceleb/FakeVideo-RealAudio/Caucasian (European)/women/id00071/00014_id00330_wavtolip.mp4\"  # change accordingly\n",
    "\n",
    "frames = run_cfn_on_video(\n",
    "    video_path=VIDEO_PATH,\n",
    "    threshold=0.6,\n",
    "    chunk_seconds=10,\n",
    "    max_seconds=None,\n",
    ")\n",
    "\n",
    "len(frames), frames[0].keys()\n",
    "\n",
    "video_fake, fake_conf, highlight = summarize_video(\n",
    "    frames,\n",
    "    prob_thresh=0.6,\n",
    "    ratio_thresh=0.3\n",
    ")\n",
    "\n",
    "video_fake, fake_conf, highlight[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Visualization: timeline and bounding boxes\n",
    "Highlight red regions where fake probability crosses threshold and draw bboxes on those frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0.0, 4.36)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build contiguous fake segments from frame-level scores\n",
    "\n",
    "def get_fake_segments(frames, prob_thresh=0.6, min_run=2):\n",
    "    mask = [f.get(\"fake_prob\", 0) >= prob_thresh for f in frames]\n",
    "    segments = []\n",
    "    start = None\n",
    "    for i, flag in enumerate(mask):\n",
    "        if flag and start is None:\n",
    "            start = i\n",
    "        if not flag and start is not None:\n",
    "            if i - start >= min_run:\n",
    "                segments.append((frames[start][\"timestamp\"], frames[i-1][\"timestamp\"]))\n",
    "            start = None\n",
    "    if start is not None and len(mask) - start >= min_run:\n",
    "        segments.append((frames[start][\"timestamp\"], frames[len(mask)-1][\"timestamp\"]))\n",
    "    return segments\n",
    "\n",
    "\n",
    "def plot_fake_timeline(frames, segments, title=\"Fake segments\"):\n",
    "    if not frames:\n",
    "        print(\"No frames available\")\n",
    "        return\n",
    "    total_time = frames[-1][\"timestamp\"] if frames else 0\n",
    "    plt.figure(figsize=(10, 1.2))\n",
    "    for s, e in segments:\n",
    "        plt.hlines(1, s, e, colors=\"red\", linewidth=6)\n",
    "    plt.xlim(0, total_time)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "segments = get_fake_segments(frames, prob_thresh=0.6, min_run=2)\n",
    "plot_fake_timeline(frames, segments)\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('annotated_fakes.mp4')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "def render_fake_bboxes(video_path, frames, prob_thresh=0.6, out_path=\"annotated_fakes.mp4\"):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    writer = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "\n",
    "    frame_map = {int(f[\"timestamp\"] * fps): f for f in frames if f.get(\"fake_prob\", 0) >= prob_thresh and f.get(\"bbox\")}\n",
    "\n",
    "    idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        info = frame_map.get(idx)\n",
    "        if info and info.get(\"bbox\"):\n",
    "            x1, y1, x2, y2 = info[\"bbox\"]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        writer.write(frame)\n",
    "        idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    return Path(out_path)\n",
    "\n",
    "render_fake_bboxes(VIDEO_PATH, frames, prob_thresh=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Technique sweeps and logging\n",
    "Compare detection techniques (thresholds, smoothing) and log results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from src.cvi.api.inference_service import summarize_video\n",
    "\n",
    "LOG_PATH = Path(\"notebooks/technique_runs.csv\")\n",
    "\n",
    "\n",
    "def apply_technique(video_path, prob_thresh=0.6, ratio_thresh=0.3, smoothing=None, label=\"base\"):\n",
    "    frames_local = run_cfn_on_video(video_path, threshold=prob_thresh)\n",
    "    if smoothing:\n",
    "        probs = np.array([f[\"fake_prob\"] for f in frames_local])\n",
    "        smooth = uniform_filter1d(probs, size=smoothing, mode=\"nearest\")\n",
    "        for f, s in zip(frames_local, smooth):\n",
    "            f[\"fake_prob\"] = float(s)\n",
    "    video_fake, fake_conf, highlight = summarize_video(frames_local, prob_thresh=prob_thresh, ratio_thresh=ratio_thresh)\n",
    "    segments = get_fake_segments(frames_local, prob_thresh=prob_thresh, min_run=2)\n",
    "    record = {\n",
    "        \"timestamp\": time.time(),\n",
    "        \"video\": video_path,\n",
    "        \"label\": label,\n",
    "        \"prob_thresh\": prob_thresh,\n",
    "        \"ratio_thresh\": ratio_thresh,\n",
    "        \"smoothing\": smoothing or 0,\n",
    "        \"video_fake\": video_fake,\n",
    "        \"fake_conf\": fake_conf,\n",
    "        \"segments\": len(segments),\n",
    "        \"segment_spans\": json.dumps(segments),\n",
    "    }\n",
    "    return record, frames_local, segments\n",
    "\n",
    "\n",
    "def log_record(record):\n",
    "    LOG_PATH.parent.mkdir(exist_ok=True)\n",
    "    if LOG_PATH.exists():\n",
    "        df = pd.read_csv(LOG_PATH)\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "    df = pd.concat([df, pd.DataFrame([record])], ignore_index=True)\n",
    "    df.to_csv(LOG_PATH, index=False)\n",
    "    return df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/backend/src/cvi/frame_causal_extractor.py:45: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(\n",
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/backend/src/cvi/frame_causal_extractor.py:45: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(\n",
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>video</th>\n",
       "      <th>label</th>\n",
       "      <th>prob_thresh</th>\n",
       "      <th>ratio_thresh</th>\n",
       "      <th>smoothing</th>\n",
       "      <th>video_fake</th>\n",
       "      <th>fake_conf</th>\n",
       "      <th>segments</th>\n",
       "      <th>segment_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.769357e+09</td>\n",
       "      <td>/Users/venturit/Documents/GitHub/FYP/CausalX-P...</td>\n",
       "      <td>base</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0, 4.36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.769357e+09</td>\n",
       "      <td>/Users/venturit/Documents/GitHub/FYP/CausalX-P...</td>\n",
       "      <td>smooth5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0, 4.36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.769357e+09</td>\n",
       "      <td>/Users/venturit/Documents/GitHub/FYP/CausalX-P...</td>\n",
       "      <td>strict</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.04, 1.8], [1.88, 4.36]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp                                              video    label  \\\n",
       "0  1.769357e+09  /Users/venturit/Documents/GitHub/FYP/CausalX-P...     base   \n",
       "1  1.769357e+09  /Users/venturit/Documents/GitHub/FYP/CausalX-P...  smooth5   \n",
       "2  1.769357e+09  /Users/venturit/Documents/GitHub/FYP/CausalX-P...   strict   \n",
       "\n",
       "   prob_thresh  ratio_thresh  smoothing  video_fake  fake_conf  segments  \\\n",
       "0          0.6           0.3          0           1   1.000000         1   \n",
       "1          0.6           0.3          5           1   1.000000         1   \n",
       "2          0.7           0.4          0           1   0.981818         2   \n",
       "\n",
       "                 segment_spans  \n",
       "0                [[0.0, 4.36]]  \n",
       "1                [[0.0, 4.36]]  \n",
       "2  [[0.04, 1.8], [1.88, 4.36]]  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a few candidate techniques and log\n",
    "candidates = [\n",
    "    {\"label\": \"base\", \"prob_thresh\": 0.6, \"ratio_thresh\": 0.3, \"smoothing\": None},\n",
    "    {\"label\": \"smooth5\", \"prob_thresh\": 0.6, \"ratio_thresh\": 0.3, \"smoothing\": 5},\n",
    "    {\"label\": \"strict\", \"prob_thresh\": 0.7, \"ratio_thresh\": 0.4, \"smoothing\": None},\n",
    "]\n",
    "\n",
    "records = []\n",
    "for cfg in candidates:\n",
    "    rec, frames_local, segments_local = apply_technique(VIDEO_PATH, **cfg)\n",
    "    records.append(rec)\n",
    "    log_record(rec)\n",
    "\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>video</th>\n",
       "      <th>label</th>\n",
       "      <th>prob_thresh</th>\n",
       "      <th>ratio_thresh</th>\n",
       "      <th>smoothing</th>\n",
       "      <th>video_fake</th>\n",
       "      <th>fake_conf</th>\n",
       "      <th>segments</th>\n",
       "      <th>segment_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.769357e+09</td>\n",
       "      <td>/Users/venturit/Documents/GitHub/FYP/CausalX-P...</td>\n",
       "      <td>base</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0, 4.36]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp                                              video label  \\\n",
       "0  1.769357e+09  /Users/venturit/Documents/GitHub/FYP/CausalX-P...  base   \n",
       "\n",
       "   prob_thresh  ratio_thresh  smoothing  video_fake  fake_conf  segments  \\\n",
       "0          0.6           0.3          0           1        1.0         1   \n",
       "\n",
       "   segment_spans  \n",
       "0  [[0.0, 4.36]]  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick the most confident technique (max fake_conf) for downstream use\n",
    "results_df = pd.DataFrame(records)\n",
    "best = results_df.sort_values(\"fake_conf\", ascending=False).head(1)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/backend/src/cvi/frame_causal_extractor.py:45: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(\n",
      "/Users/venturit/Documents/GitHub/FYP/CausalX-Project/.venv/lib/python3.11/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('annotated_fakes.mp4')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: use the best technique's frames to draw bboxes and timeline\n",
    "best_cfg = candidates[int(best.index[0])]\n",
    "rec_best, frames_best, segments_best = apply_technique(VIDEO_PATH, **best_cfg)\n",
    "plot_fake_timeline(frames_best, segments_best, title=f\"Best: {best_cfg['label']}\")\n",
    "render_fake_bboxes(VIDEO_PATH, frames_best, prob_thresh=best_cfg['prob_thresh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4mqtjuikI6f"
   },
   "source": [
    "**SECTION 8 — Video-Level Aggregation (EXPERIMENTAL)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dY-aObCkPNn"
   },
   "source": [
    "Aggregation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "VNbh8q_nkM1R"
   },
   "outputs": [],
   "source": [
    "def aggregate(probs, method=\"topk\"):\n",
    "    if method == \"mean\":\n",
    "        return probs.mean()\n",
    "    if method == \"max\":\n",
    "        return probs.max()\n",
    "    if method == \"topk\":\n",
    "        k = int(0.2 * len(probs))\n",
    "        return np.sort(probs)[-k:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-exyD00kWnT"
   },
   "source": [
    "**SECTION 9 — CVI (Visualization Logic)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coGghrD1kayP"
   },
   "source": [
    "Timestamp Highlighting Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "4FCgAgYqkbEd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fake_frames = [t \u001b[38;5;28;01mfor\u001b[39;00m t, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mtimes\u001b[49m, probs) \u001b[38;5;28;01mif\u001b[39;00m p > \u001b[32m0.6\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'times' is not defined"
     ]
    }
   ],
   "source": [
    "fake_frames = [t for t, p in zip(times, probs) if p > 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5E3Cg-wkgHI"
   },
   "source": [
    "**SECTION 10 — Final System Comparison**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
